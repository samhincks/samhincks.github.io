
I have found the Myers Briggs to be a useful thinking tool both for making quick better-than-chance and intuition inferences about acquaintances, guiding my inquiry in a kind of overview first, zoom-and-filter, then details on demand approach to getting to know somebody. 

MB predicts that basic information processing properties of a person’s mind interact to shape an individual’s personality. According to the theory, there are four information processing attributes in particular which exert profound effect on a person’s goals, strengths, and weaknesses. Each classification has two possible values, resulting in 16 distinct personalities.

It is clear from neuroimaging that the brain is a computer driven by two independent and anti-correlated networks which update internal and external configurations to somehow acheive short term and long term proliferation. These networks have in common that they map inputs to outputs by triggering a cascade of activations in a neural network that is best thought of as a hierarchy, with some percentage of the neurons more intimately wedded the networks inputs and others hierarchically more advanced. It is this cascade and the informational representations that the underlying activations represent which we enjoy as experience. 
But the  
And it is these informational representations which we enjoy as experience.
 these activation patterns represent knowledge and are implemented hierarchically, with some set of neurons   

  The exogenous network process sensory data and control the actions of the individuals. The endogenous network processes memories and future simulation, and upholds the description of a self. 

Let us assume these are the two major if vague networks that comprise the information processing of the brain. In that case, what would you expect to be the major points of variation among different individuals? What are the possible tradeoffs in a system with two major networks that compete for scarce resources? 

Here are four trade-offs:
1. During what situations does an individual engage the endogenous vs. exogenous network? 
2. How abstract are the internal configurations in the endogenous network?
3. How comfortable is the endogenous network with the fact that the exogenous network controls action? 
4. Which is relatively more robust in the individual, input networks or output networks? 

With possible exception of number 3 (which may require introducing a more networks), these four dimensions map cleanly onto the information processing dimensions proposed by Myers-Briggs. 

1. An introvert regresses into endogenous networks when the information bandwidth between it and a social environment is too high or too low. An extrovert more reliably engages an exogenous networks during social situations by action or interest. 
2. An intuitive processes higher order abstractions separated from the lower level computations of the senses. A sensing type does not suffer these abstractions, instead enjoying more immediate immersion with the senses.
3. A feeling type trusts implicit (lower level) hunches about the best course of action. A thinking type prefers to reason about 
4. 

I'm not sure that Carl Jung who originally figured out that the MB dimensions were very predictive of behavior was reasoning in this way from the ground up from information specifications, but it seems to me the right approach ultimately, if you are confident in the information processing specifications you propose.

 data from the senses, processing it with what we will call the exogenous input network. 



Let’s try to reason our way to what those attributes might be. I convinced myself to adopt the MB intuition pump when viewed the scale through a computer scientists eyes. So, as a thought experiment, let’s step back for a minute, and attempt to come up with a personality scale for a computer. Here are some questions we might ask.
1. How much does the computer process raw input? Are the symbols it winds up acting upon hierarchically removed from raw input or more faithful to the original, literal representation?
2. To what extent does the input stem from internal processes? To what extent is the input supplied from the world?
3. Do the programs which act on the input aim to extract truth or are they in search of promoting utility / welfare? 
4. What percentages of the program is dedicated towards processing input versus acting on it?

Let’s consider two programs. Program A: was rigged so that most of its input had internal origins,  it endlessly processed this input it more abstract and hierarchically distant symbols, it acted on this data to promote utility and not truth, and it dedicated relatively more of its computational labor towards processing data than acting  on it.

Program B was rigged in the exact opposite manner. Most functions had input with origins from the real world, and it tends to undergo relatively little processing before it is acted on. The decisive functions judge whether or not information is true. And these decisive functions hog most of the system’s computational power. 

How would program A and B differ in terms of robo-personality? 
 
Equipped to process external states, computer B would be curios about the real world; it would position itself so that it could tap the richest source of external input (other computer’s). Equipped to process internal states, Computer A would appear to isolate itself more from other machines. From an observer’s point of view, it would be harder to figure out what it was actually computing. It would very likely have an internally sophisticated mental life, rich with ideals, but nobody would know about it. 

Though secretive, Computer A would appear the more abstract piece of machinery. The symbols it acts on would not be mere points of light or sound vibrations; these would have all been distilled and filtered for meaning. A series of black lines would register as a word with meaning. Computer B might seem more observant, and it’s conclusions would might be more literal and factual. They might correspond more to reality. 

A logical truth extractor, Computer B would generate conclusions which serve it productively but might displease its audience, especially if those truths were directed at the audience members. Computer A, which judged ideas on positive-versus negative dimension, would have the opposite effect, generating conclusions which user’s of the program appreciated but had a low coherence to reality. It would be emotional instead of logical.

Finally, computer B (with well endowed decision-making functions) would have spare computation for calculating matters not immediately relevant to it. Even if present information was incomplete, it  might have settled a matter which the user only needs to know months into the future. It would be on top of its shit. Computer A (with well endowed information-processing functions) would not have good plans; it would be too busy processing data pertaining to the moment; lacking a plan, it would seem spontaneous.

So Computer A is internally-oriented and abstract, utilitarian/emotional, and spontaneous.
Computer B is externally-oriented and concrete, logical, and has planned things in advance.

How would I use computer A differently from computer B?
Computer A is a thinker, computer B is a doer.
Computer A is a friend, computer B is a worker.
Computer A is a lover, computer B is a partner. 
Computer A is a writer, computer B is an administrator. 

Computer a 



Turns out the brain is not that different from a computer. It is able to behave in a surprisingly intelligent manner for the same reason a computer does. Programs can be instantiated on constellations of networks; the input to certain constellations of networks is better described as the output 

There are those who see the world as the world, and then there are those who see the world, and then their brain space plus the world. I think the second is most important. 